{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "german-blank",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collaborative-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.utils\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import words\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline    \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, plot_confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acting-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframe\n",
    "df = joblib.load(\"exports/dataframe.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-hometown",
   "metadata": {},
   "source": [
    "# Build vocabulary\n",
    "Build the vocabulary over all words of our dataset, because the vocabulary can not be changed after the model is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dynamic-ballet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exports/vocab.sav']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected_words = set()\n",
    "for text in df[\"clean_text\"]:\n",
    "    for word in text:\n",
    "        collected_words.add(word)\n",
    "\n",
    "wordlist_nltk = words.words()\n",
    "\n",
    "wordlist_github = [] # https://github.com/dwyl/english-words\n",
    "with open(\"resources/words-dwyl-github.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        wordlist_github.append(line[:-1])\n",
    "\n",
    "wordlist_github_nltk_combined = wordlist_github + wordlist_nltk\n",
    "\n",
    "wordlist_github_nltk_combined_lower = [x.lower() for x in wordlist_github_nltk_combined]\n",
    "intersection_github_nltk_combined_lower = collected_words.intersection(wordlist_github_nltk_combined_lower)\n",
    "vocabulary = intersection_github_nltk_combined_lower\n",
    "len(vocabulary)\n",
    "\n",
    "joblib.dump(vocabulary, \"exports/vocab.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-essex",
   "metadata": {},
   "source": [
    "# Prepare dataset parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reserved-guarantee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62701"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "entitled-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = df[df[\"spam\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "realistic-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham = df[df[\"spam\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mounted-glucose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34291"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "random-drilling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28410"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "engaged-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 25k for balanced dataset\n",
    "amount = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tested-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshuffle dataframes (currently spam and ham are strictly separated)\n",
    "df_spam = sklearn.utils.shuffle(df_spam)\n",
    "df_ham = sklearn.utils.shuffle(df_ham)\n",
    "\n",
    "# fix indices\n",
    "df_spam = df_spam.reset_index(drop=True)\n",
    "df_ham = df_ham.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "brave-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create balanced df (25k spam and 25k ham mails) for training the model\n",
    "df_model_train = df_spam[:amount].append(df_ham[:amount])\n",
    "df_model_train = sklearn.utils.shuffle(df_model_train)\n",
    "df_model_train = df_model_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "received-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the rest of df_spam and df_ham but keep the new df (df_model_test) balanced\n",
    "df_model_test = df_spam[amount:28410].append(df_ham[amount:28410])\n",
    "df_model_test = sklearn.utils.shuffle(df_model_test)\n",
    "df_model_test = df_model_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "expressed-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for cross-validation, contains train and test dataset, balanced\n",
    "df_balanced = df_model_train.append(df_model_test)\n",
    "df_balanced = sklearn.utils.shuffle(df_balanced)\n",
    "df_balanced = df_balanced.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-bradford",
   "metadata": {},
   "source": [
    "# Estimator test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "intelligent-still",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for text in df_model_train[\"clean_text\"]:\n",
    "    msg = ' '.join([row for row in text])\n",
    "    corpus.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "familiar-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(vocabulary=vocabulary)\n",
    "x_train = tfidf.fit_transform(corpus).toarray()\n",
    "y_train = df_model_train[\"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "combined-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for text in df_model_test[\"clean_text\"]:\n",
    "    msg = ' '.join([row for row in text])\n",
    "    corpus.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mediterranean-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tfidf.fit_transform(corpus).toarray()\n",
    "y_test = df_model_test[\"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-cleaner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: MultinomialNB()\n",
      "Train-Duration: 8.211855173110962 s\n",
      "Accuracy: 0.9523460410557185 \n",
      "\n",
      "Estimator: RandomForestClassifier()\n",
      "Train-Duration: 555.2905266284943 s\n",
      "Accuracy: 0.978592375366569 \n",
      "\n",
      "Estimator: KNeighborsClassifier()\n",
      "Train-Duration: 8.466284036636353 s\n",
      "Accuracy: 0.7541055718475074 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# try different estimators for the model \n",
    "classifiers = [MultinomialNB(), \n",
    "               RandomForestClassifier(),\n",
    "               KNeighborsClassifier(),\n",
    "               #SVC()\n",
    "              ]\n",
    "\n",
    "for cls in classifiers:\n",
    "    time_start = time.time()\n",
    "    cls.fit(x_train, y_train)\n",
    "    time_end = time.time()\n",
    "    print(\"Estimator:\", cls)\n",
    "    print(\"Train-Duration:\", time_end - time_start, \"s\")\n",
    "    score = cls.score(x_test, y_test)\n",
    "    print(\"Accuracy:\", score, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cheap-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC() will no longer be considered due to extremly long run time\n",
    "# after 8 hours it still hasn't finished ...\n",
    "#classifiers = classifiers[:-1] # remove SVC() from list (if not uncomment in classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "graduate-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest worked the best (highest accuracy) and was the most efficient one for our tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-tribe",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "multiple-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for text in df_balanced[\"clean_text\"]:\n",
    "    msg = ' '.join([row for row in text])\n",
    "    corpus.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "athletic-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(vocabulary=vocabulary)\n",
    "x_all = tfidf.fit_transform(corpus).toarray()\n",
    "y_all = df_balanced[\"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "neural-marketplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "refined-guatemala",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: MultinomialNB()\n",
      "Crossval-Duration: 913.7169682979584 s\n",
      "Mean accuracy: 0.950703977472721 \n",
      "\n",
      "Estimator: RandomForestClassifier()\n",
      "Crossval-Duration: 5695.442259311676 s\n",
      "Mean accuracy: 0.9771383315733896 \n",
      "\n",
      "Estimator: KNeighborsClassifier()\n",
      "Crossval-Duration: 2097.342945575714 s\n",
      "Mean accuracy: 0.7539246744104189 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# cross-validation using only clean_text with TFIDF as features\n",
    "for cls in classifiers:\n",
    "    time_start = time.time()\n",
    "    cv_score = cross_val_score(cls, x_all,y_all,scoring=\"accuracy\", cv=10)\n",
    "    time_end = time.time()\n",
    "    print(\"Estimator:\", cls)\n",
    "    print(\"Crossval-Duration:\", time_end - time_start, \"s\")\n",
    "    mean_score = cv_score.mean()\n",
    "    print(\"Mean accuracy:\", mean_score, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "interim-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so looks like RandomForest performs best\n",
    "# lets try to add more features and do the cross-validation again to see if this improves the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acknowledged-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = np.append(x_all, df_balanced[[\"tokens\", \"chars\"]].to_numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "reverse-wrist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.,    0.,    0., ...,    0.,   77.,  489.],\n",
       "       [   0.,    0.,    0., ...,    0.,  161., 1528.],\n",
       "       [   0.,    0.,    0., ...,    0.,   61.,  433.],\n",
       "       ...,\n",
       "       [   0.,    0.,    0., ...,    0.,  157., 1036.],\n",
       "       [   0.,    0.,    0., ...,    0.,  238., 1682.],\n",
       "       [   0.,    0.,    0., ...,    0.,  196., 1159.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "logical-syria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: MultinomialNB()\n",
      "Crossval-Duration: 1038.6484024524689 s\n",
      "Mean accuracy: 0.8724744808166138 \n",
      "\n",
      "Estimator: RandomForestClassifier()\n",
      "Crossval-Duration: 5761.310852527618 s\n",
      "Mean accuracy: 0.9793206617388244 \n",
      "\n",
      "Estimator: KNeighborsClassifier()\n",
      "Crossval-Duration: 2052.179085254669 s\n",
      "Mean accuracy: 0.7200281590989088 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross-validation using clean_text with TFIDF AND number of tokens and number of chars as features\n",
    "for cls in classifiers:\n",
    "    time_start = time.time()\n",
    "    cv_score = cross_val_score(cls, x_all,y_all,scoring=\"accuracy\", cv=10)\n",
    "    time_end = time.time()\n",
    "    print(\"Estimator:\", cls)\n",
    "    print(\"Crossval-Duration:\", time_end - time_start, \"s\")\n",
    "    mean_score = cv_score.mean()\n",
    "    print(\"Mean accuracy:\", mean_score, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bizarre-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest is still the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "federal-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by using more features (#tokens, #chars) we could improve the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "statutory-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest only clean_text: 0.9771383315733896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "signed-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest clean_text, #chars, #tokens: 0.9793206617388244"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-february",
   "metadata": {},
   "source": [
    "# Export final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "earned-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ours experiments showed that the best estimator is RandomForest with TFIDF AND #tokens, #chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "international-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for text in df_model_train[\"clean_text\"]:\n",
    "    msg = ' '.join([row for row in text])\n",
    "    corpus.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "critical-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(vocabulary=vocabulary)\n",
    "x_train = tfidf.fit_transform(corpus).toarray()\n",
    "x_train = np.append(x_train, df_model_train[[\"tokens\", \"chars\"]].to_numpy(), axis=1)\n",
    "y_train = df_model_train[\"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "closing-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for text in df_model_test[\"clean_text\"]:\n",
    "    msg = ' '.join([row for row in text])\n",
    "    corpus.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eligible-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tfidf.fit_transform(corpus).toarray()\n",
    "x_test = np.append(x_test, df_model_test[[\"tokens\", \"chars\"]].to_numpy(), axis=1)\n",
    "y_test = df_model_test[\"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "adapted-marathon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: RandomForestClassifier()\n",
      "Train-Duration: 498.00077414512634 s\n",
      "Accuracy: 0.9787390029325513 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "classifiers = [RandomForestClassifier()]\n",
    "\n",
    "for cls in classifiers:\n",
    "    time_start = time.time()\n",
    "    cls.fit(x_train, y_train)\n",
    "    time_end = time.time()\n",
    "    print(\"Estimator:\", cls)\n",
    "    print(\"Train-Duration:\", time_end - time_start, \"s\")\n",
    "    score = cls.score(x_test, y_test)\n",
    "    print(\"Accuracy:\", score, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "organized-florence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exports/model.sav']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export model\n",
    "joblib.dump(classifiers[0], \"exports/model.sav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
